%% Aide-mémoire
\documentclass[10pt, french, landscape]{article}
%% -----------------------------
%% Préambule
%% -----------------------------
\input{cheatsht-preamble.tex}

% Couleur de la page
%\pagecolor{gray!10!white}


%% -----------------------------
%% Début du document
%% -----------------------------
\begin{document}

\small
\begin{multicols*}{3} % Nombre de colonnes (peut être changé plus tard.)
\section{Probabilités conditionnelles}
\begin{enumerate}[label=\faAngleRight]
\item Distribution conditionnelle : 
\begin{align*}
\prob{X_1 = x_1 | X_2 = x_2} & = \frac{\prob{X_1 = x_1, X_2 = x_2}}{\prob{X_2 = x_2}} \\
\end{align*}

\item L'espérance d'une fonction conditionnelle : 
\begin{align*}
\esp{g(X_1) | X_2 = x_2} = \sum_{i=0}^{\infty} g(x) \prob{X_1 = x_1 | X_2 = x_2}
\end{align*}

\item La variance d'une fonction conditionnelle :
\begin{align*}
Var(g(X_1) | X_2) = \esp{g(X_1)^2 |X_2} - \esp{g(X_1) | X_2}^2
\end{align*}

\item L'espérance conditionnelle : 
\begin{align*}
\esp{X_1} 	& = \esp{\esp{X_1 | X_2}} = \sum_{x_2 = 0}^{\infty} \esp{X_1 | X_2} \prob{X_2 = x_2} \\
\esp{X_1}	& = \esp{\esp{X_1 | X_2}} = \int_{-\infty}^{\infty} \esp{X_1 | X_2} f_{X_2}(x_2) d x_2 \\
\end{align*}

\item La variance conditionnelle : 
\begin{align*}
Var(X_1) = \esp{Var(X_1 | X_2)} + Var\left( \esp{X_1 | X_2} \right)
\end{align*}
\end{enumerate}

Lorsqu'il y a 3 v.a., l'espérance devient
\begin{align*}
\esp{X_1 | X_2}	& = \esp{\esp{X_1 | X_2, X_3} | X_2} \\
	& = \sum_{x_3 = 0}^{\infty} \esp{X_1 | X_2, X_3} \prob{X_3 = x_3 | X_2 = x_2} \\
	& = \int_{-\infty}^{\infty} \esp{X_1 | X_2, X_3} f_{X_3| X_2}(x_3 | x_2) dx_3
\end{align*}
Et la variance conditionnelle devient
\begin{align*}
Var(X_1) = \esp{Var(X_1 | X_2, X_3)}  + Var \left( \esp{X_1 | X_2, X_3} \right)
\end{align*}

\subsection*{Poisson composée}
\begin{enumerate}[label=\faAngleRight]
\item Soit $S = X_1 + ... + X_N$, où les $X_i$ sont \textit{iid}, $N \sim Pois(\lambda)$ est stochastiquement indépendant des $X_i$. Alors, on a
\begin{align*}
\esp{S h(S)} = \lambda \esp{X h(S+X)}
\end{align*}

\item On peut aussi trouver que
\begin{align*}
\esp{S^n} = \lambda \sum_{j=0}^{n-1} \binom{n-1}{j} \esp{S^j} \esp{X^{n-j}}
\end{align*}
\end{enumerate}

\subsection*{Mesures de risque}
\begin{enumerate}[label=\faAngleRight]
\item Value-At-Risk (VaR) : représente le quantile au niveau $\kappa$ de $X$.
\begin{align*}
VaR_\kappa(X) = F_X^{-1}(\kappa) = \inf \{ x \geq 0 : F_X(x) \geq \kappa \}
\end{align*}

\item Tail Value-At-Risk (aussi appelée \textit{Conditional Tail Expectation})  : représente la perte moyenne de $X$, sachant qu'elle est au dessus de la valeur $VaR_\kappa(X)$.
\begin{align*}
TVaR_\kappa(X) & = \esp{X | X > VaR_\kappa(X)} \\
	& = \int_{0}^{\infty} x f_{X | X > VaR_\kappa(X)}(x) dx \\
	& = \int_{VaR_\kappa(X)}^{\infty} \frac{x f_X(x)}{\overline{F}_X(VaR_\kappa(X))} dx \\
	& = \frac{1}{1 - \kappa} \int_{VaR_\kappa(X)}^{\infty} x f_X(x) dx \\
\end{align*}
\end{enumerate}
















\section{Chaînes de Markov}
\subsection*{Définition}
Une chaîne de Markov est homogène si
\begin{align*}
\prob{X_{n+1} = j | X_{n}=i, ..., X_0 = i_0} & = \prob{X_{n+1} = j | X_n = i}  \\
 & = p_{ij} \\
\end{align*}
On définit la matrice des probabilités de transition
\begin{align*}
P = [p_{ij}]_{i \times j}  
\end{align*}

\subsection*{Équation de Chapman-Kolmogorov}
\begin{align*}
p_{ij}^{(n)} 	& = \prob{X_{k+n} = j | X_k = i} \\
p_{ij}^{(n+m)} 	& = \sum_{k=0}^{\infty} p_{ik}^{(n)} p_{kj}^{(m)} \\
\end{align*}
Note : soit $P$ la matrice des probabilités de transition. On peut trouver $P^{(n+m)} = P^{(n)} \cdot P^{(m)}$, avec $P^{(n)} = P^n = P\cdot P \cdot P \cdot ... \cdot P$.

\begin{align*}
\prob{X_n = j} & = \sum_{i=0}^{\infty} p_{ij}^{(n)} p_{x_0}(i) \\
	& = \sum_{i=0}^{\infty} \prob{X_n = j | X_0 = i} \prob{X_0 = i} \\
\end{align*}

\subsection*{États accessibles et communicants}
\begin{enumerate}[label=\faAngleRight]
\item $j$ est accessible de $i$ si $p_{ij}^{(n)} >0$, pour $n \in \naturels$.

\item si $i$ et $j$ sont accessibles réciproquement ($i \leftrightarrow i$), alors ils sont \textbf{communicants}. Ils forment donc une classe (ainsi que les autres états communicants).

\item Une chaîne de Markov est dite \underline{irréductible} si elle est composée d'une seule classe.
\end{enumerate}

\subsubsection*{Propriété d'une classe}
\begin{enumerate}[label=\faCheck]
\item Réflexibilité : $p_{ii}^{(0)} = 1$.
\item Symétrie : $i \leftrightarrow j$ est équivalent à $j \leftrightarrow i$.
\item Transitivité : si $i$ communique avec $j$ (i.e. $p_{ij}^{(n)} >0$) et que $j$ communique avec $k$ (i.e. $p_{jk}^{(m)}>0$), alors
\begin{align*}
p_{ik}^{(n+m)} = \sum_{r=0}^{\infty} p_{ir}^{(n)} p_{rk}^{(m)} \geq p_{ij}^{(n)} p_{jk}^{(m)} > 0
\end{align*}
\end{enumerate}

\subsection*{États récurrents, transcients et absorbants}
\begin{enumerate}[label=\faAngleRight]
\item $f_{ii}$ : probabilité de revenir éventuellement à l'état $i$ en ayant comme point de départ $i$.
\item Si $f_{ii} = 1$, $i$ est récurrent. Si $f_{ii} < 1$, alors $i$ est transcient.
\item Aussi, si $\sum_{n=1}^{\infty} p_{ii}^{(n)} = \infty$, alors $i$ est récurrent. Sinon, il est transcient.
\item Si l'état $i$ est récurrent et que $i \leftrightarrow j$, alors $j$ est récurrent aussi.
\item $f_{ii}^{(n)}$ : probabilité de revenir à l'état $i$ pour la première fois après $n$ étapes.
\item Une chaîne de Markov irréductible avec espace d'état fini \textbf{n'a que des états récurrents}.
\item \textbf{État absorbant} : $j$ est un état absorbant si $p_{jj} = 1$. De plus, Si $j$ est un état absorbant, alors
\begin{align*}
f_{ij} = \sum_{k=0}^{m} p_{ik} f_{kj}
\end{align*}
\end{enumerate}

\subsection*{Probabilité limites}
\begin{enumerate}[label=\faAngleRight]
\item \textbf{État périodique} : si l'état a une période $d$, alors il sera possible de revenir à cet état après $n$ étapes, qui est un multiple de $d$. i.e
\begin{align*}
d(i) = P.G.C.D\{n \in \naturels ~ | ~ p_{ii}^{(n)} > 0 \}
\end{align*}
\item si $d(i)=1$, alors l'état $i$ est \textbf{apériodique}.
\item La périodicité est une propriété de classe : si $i \leftrightarrow j$, alors $d(i) = d(j)$.
\item Le temps de retour moyen pour l'état $i$ est défini par
\begin{align*}
\mu_{ii} = \sum_{n=1}^{\infty} n f_{ii}^{(n)}
\end{align*}

\item \textbf{État récurrent positif} : si, à partir de l'état $i$, le temps de retour moyen $\mu_{ii}$ à l'état $i$ est fini, alors l'état $i$ est récurrent positif.

\item \textbf{État ergodique} : un état qui est à la fois apériodique et récurrent positif.

\item Si une Chaîne de Markov est irréductible et que tout ses états sont ergodiques, alors
\begin{enumerate}[label=(\arabic*)]
	\item $	\lim_{n \to \infty} p_{ij}^{(n)} = \pi_j < \infty$
	\item $\pi_j = \sum_{i=0}^{\infty} \pi_i p_{ij}$
	\item $\sum_{j=0}^{\infty} \pi_j = 1$
\end{enumerate}

\item On peut alors résoudre un système d'équations pour trouver nos $\pi_i$.
\end{enumerate}

\section{Processus de Poisson}
Soit $N(t)$ le nombre d'évènements qui se sont produits dans l'intervalle $t$.

\subsection*{Définitions}
\begin{definition}[Définition 1]
Un processus de dénombrement $\{N(t) ; t \geq 0 \}$ est dit un processus de Poisson avec $\lambda >0$ ssi
\begin{enumerate}[label=(\arabic*)]
\item $N(0)=0$
\item Le processus a des accroissements indépendants, i.e pour $0 \leq t_1 \leq t_2 < t_3$, les accroissements $(N(t_3) - N(t_2))$ et $(N(t_2)-N(t_1))$ sont stochastiquement indépendants.
\item $\forall t \ $, $(N(s+t) - N(s)) \sim Pois(\lambda t)$. Alors,
\begin{align*}
\prob{N(s+t) - N(s) = n} = \frac{(\lambda t)^n e^{-\lambda t}}{n!}
\end{align*}
\end{enumerate}
\end{definition}

\begin{definition}[Définition 2]
Un processus de dénombrement $\{N(t) ; t \geq 0 \}$ est dit un processus de Poisson avec $\lambda>0$ ssi
\begin{enumerate}[label=(\arabic*)]
\item $N(0)=0$
\item a des accroissements indépendants et stationnaires
\item $\prob{N(h) = 1} = \lambda h + o(h)$
\item $\prob{N(h) \geq 2} = o(h)$
\end{enumerate}
Avec $o(h)$ une fonction où $f(h) = o(h)$ si $\lim_{n \to \infty} \frac{f(h)}{h} = 0$.
\end{definition}
On peut prouver que ces 2 définitions sont équivalents.

\subsection*{Temps séparant 2 évènements successifs}\begin{enumerate}[label=\faAngleRight]
\item Soit $T_i$ le temps entre le $(i-1)$\up{e} et le $i$\up{e} évènement.

\item Alors, $T_n \sim Exp (\lambda)$.

\item Soit $S_n$ le moment où se produit le $i$\up{e} évènement. On a
\begin{align*}
S_n = \sum_{i=1}^{n} T_i
\end{align*}
\item On peut facilement prouver que $S_n \sim \Gamma(n, \lambda)$.

\item Si $N(t) \geq n$, alors nécessairement $S_n \leq t$.
\end{enumerate}

\subsection*{Processus de Poisson avec évènements de type I et II}
\begin{enumerate}[label=\faAngleRight]
\item Soit un Processus de Poisson $\{N(t) ; t \geq 0 \}$ où il peut y avoir un évènement de type I avec probabilité $p$ ou un de type II avec probabilité $q$.
\item Nécessairement, on a
\begin{align*}
N(t) = N_1(t) + N_2(t)
\end{align*}
Avec $N_1(t)$ et $N_2(t)$ qui sont stochastiquement indépendants.

\item $N_i(t) \sim Pois(\lambda p_i t)$, où $p_i$ est la probabilité que l'évènement de type $i$ se produise.
\end{enumerate}


\subsection*{Distribution conditionnelle des temps d'occurence}
\begin{itemize}
\item Pour un processus de Poisson $\{ N(t) ; t \geq 0 \}$, la distribution conditionnelle des temps d'occurence $S_1, ... S_n$ sachant que $N(t) = n$ est définie par
\begin{align*}
f_{S_1, ..., S_n | N(t)}(s_1, ..., s_n | n) = \frac{n!}{t^n}
\end{align*}
pour $0 < s_1 < ... < s_n$.

\item La distribution de $S_1, ..., S_n | N(t) = n$ a la même distribution que les statistiques d'ordre : 
\begin{align*}
U_{(1)}, ..., U_{(n)} \sim U(0,t)
\end{align*}
\end{itemize}

\end{multicols*}

%% -----------------------------
%% Fin du document
%% -----------------------------
\end{document}