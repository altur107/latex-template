%% Aide-mémoire
\documentclass[10pt, french, landscape]{article}
%% -----------------------------
%% Préambule
%% -----------------------------
\input{cheatsht-preamble.tex}

% Couleur de la page
%\pagecolor{gray!10!white}


%% -----------------------------
%% Début du document
%% -----------------------------
\begin{document}

\small
\begin{multicols*}{3} % Nombre de colonnes (peut être changé plus tard.)
\setcounter{section}{2}

\section{Processus de Poisson}
\subsection*{Processus de Poisson non-homogène}
\begin{definition}[Définition]
Un processus de dénombrement $\{ N(t) ; t \geq 0 \}$ est dit être un processus de Poisson non-homogène avec fonction d'intensité $\lambda(t)$ si
\begin{enumerate}[label=(\arabic*)]
\item $N(0) = 0$ ;
\item $\{ N(t) ; t \geq 0 \}$ a des accroissements indépendants ;
\item $\prob{N(t+h) - N(t) = 1} = \lambda(t) h + o(h)$ ;
\item $\prob{N(t+h) - N(t) \geq 2} = o(h)$ où $o(h)$ est une fonction négligeable.
\end{enumerate}
\end{definition}

\subsubsection*{Proposition 1}
\[\prob{N(t+s) - N(t) = n}  = \frac{\left(m(t+s) - m(s) \right)^n}{n!} e^{-(m(t+s) - m(s))} \]
où $m(t) = \int_{0}^{t} \lambda(x) dx$. On a alors que
\[N(t+s) - N(s) \sim Pois(m(t+s) - m(s))\]


\subsubsection*{Proposition 2}
Si $S_n$ désigne le temps d'occurence du $n$\up{e} évènement, alors
\[f_{S_n}(t) = \lambda(t) \frac{m(t)^{n-1}}{(n-1)!} e^{-m(t)} \]

\subsubsection*{Proposition 3}
Si $T_n = S_{n} - S_{n-1}$, alors on a, pour $n \geq 2$,
\[f_{T_n}(t) = \frac{1}{(n-2)!} \int_{0}^{\infty} \lambda(s) \lambda(t+s) m(s)^{n-2} e^{-m(t+s)} ds \]

\columnbreak % forcer le changement de colonne
\subsection*{Processus de Poisson composé}
\begin{definition}[Définition]
Un processus stochastique $\{ N(t) ; t \geq 0  \}$ est dit être un processus de Poisson composé s'il peut être représenté comme suit : 
\[X(t) = \sum_{i=1}^{N(t)} Y_i\]
où $\{ N(t) ; t \geq 0  \}$ est un Processus de Poisson avec paramètre $\lambda > 0$ et $\{ Y_i ; i \in \naturels \}$ est une suite de v.a. \emph{iid} indépendantes de $N(t)$.
\end{definition}

\subsubsection*{Proposition 1}
Soit $\{ X(t) ; t \geq 0 \}$ un processus de Poisson composé avec paramètre $\lambda > 0$ et supposons que $\prob{Y_i = \alpha_j} = p_j$, $\sum p_j = 1$. Alors,
\[X(t) = \sum_j \alpha_j N_j(t) \]
où $N_j(t)$ est le nombre de fois que se produit l'évènement $\alpha_j$ dans l'intervalle de temps $[0,t]$, et $\{N(t) ; t \geq 0  \}$ forme une suite de v.a. indépentantes telles que $N_j(t) \sim Pois(\lambda p_j t$. \\
Lorsque $t \to \infty$, alors $X(t)$ est asymptotiquement normal, i.e.
\[X(t) \sim \mathcal{N}\left( \lambda t \esp{Y}, \lambda t \esp{Y^2} \right)\]

\subsubsection*{Proposition 2}
Si $\{ X(t) ; t \geq 0 \}$ et $\{ Y(t) ; t \geq 0 \}$ sont 2 processus de Poisson composés indépendants avec paramètres et fonctions de répartition $\lambda_1, F_{X_1}$ et $\lambda_2, F_{Y_1}$ respectivement, alors $\{ X(t) + Y(t) ; t \geq 0 \}$ est aussi un processus de Poisson composé avec paramètre $\lambda_1  \lambda_2$ et fonction de répartition $F_{X_1 + Y_1}$ telle que
\[F_{X_1 + Y_1} = \frac{\lambda_1 F_{X_1} + \lambda_2 F_{Y_1}}{\lambda_1 + \lambda_2}  \]


\columnbreak % forcer le changement de colonne
\subsection*{Processus de Poisson conditionnel}
\begin{definition}[Définition]
Un processus de dénombrement avec un taux aléatoire $\Lambda > 0$ est un processus de Poisson conditionnel si $\{ N(t) | \Lambda = \lambda ; t \geq 0 \}$ est un processus de Poisson avec taux $\lambda > 0$.
\end{definition}

\subsubsection*{Rappel sur la loi Gamma}
La fonction de répartition de la loi Gamma, lorsque $\alpha \in \entiers$, est définie par
\[F_X(x) = 1 - \sum_{k=1}^{\alpha-1} \frac{(\lambda x)^k e^{-\lambda x}}{k!}\]


\subsubsection*{Remarques importantes}
\begin{enumerate}[label=(\arabic*)]
\item Un processus de Poisson conditionnel a des accroissements stationnaires (i.e. l'accroissement ne dépend pas d'où on est, mais plutôt de l'intervalle de temps) ; 
\item Mais le processus de Poisson conditionnel n'a pas nécessairement des accroissements indépendants ;
\item Identité Poisson-Gamma : si on a $\Lambda \sim \Gamma(m, \theta)$, alors\footnote{Être capable de faire cette démonstration pour l'examen}
\[N(t) \sim NB\left(r = m, p = \frac{\theta}{\theta + t} \right) \]

\item L'espérance et la variance d'un processus de Poisson conditionnel sont définies par
\begin{align*}
\esp{N(t)} & = t \esp{\Lambda} \\
\variance{N(t)} & =  t \esp{\Lambda} + t^2 \variance{\Lambda}
\end{align*}

\item En utilisant le théorème de Bayes, on peut trouver la fonction de répartition $F_{\Lambda | N(t)}(x | n)$ et fonction de densité $f_{\Lambda | N(t)}(x | n)$ telles que
\begin{align*}
F_{\Lambda | N(t)}(x | n)	& = \frac{\prob{\Lambda \leq x | N(t) = n}}{\prob{N(t) = n}} \\
& = \frac{\prob{N(t) = n | \Lambda} f_\Lambda(\lambda) d \lambda}{\int_{0}^{\infty} \prob{N(t) = n | \Lambda = \lambda} f_\Lambda(\lambda) d\lambda} \\
\end{align*}

\item On a, $\forall t > 0$,
\begin{align*}
\prob{N(t) > n} = \int_{0}^{\infty} \overline{F}_{\Lambda}\left( \frac{x}{n} \right) \frac{x^n}{n!} e^{-x} dx
\end{align*}
\end{enumerate}

\section{Processus de renouvellement}
\subsection*{Définitions générales}
\begin{enumerate}[label=\faAngleRight]
\item $T_n$ : intervalle de temps entre le $(n-1)$\up{e} et le $n$\up{e} renouvellement ;
\item $S_n = \sum_{i=1}^{n} T_i$ : le temps d'occurence du $n$\up{e} renouvellement. On va souvent noter $S_{N(t)}$, avec $N(t)$ comme temps d'arrêt du processus\footnote{$N(t)$ est le temps d'arrêt dans le sens où on cesse le processus de dénombrement lorsqu'on atteint $N(t)$.}

\end{enumerate}

\subsection*{Fonction de renouvellement}


\subsection*{Théorèmes limites}
\begin{enumerate}[label=(\arabic*)]
\item On a que $N(\infty) = \infty$ avec probabilité 1. De plus,
\begin{align*}
\frac{N(t)}{t} \leftarrow \frac{1}{\mu}
\end{align*}

\end{enumerate}




\end{multicols*}

%% -----------------------------
%% Fin du document
%% -----------------------------
\end{document}